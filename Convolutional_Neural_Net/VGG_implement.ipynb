{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3dffedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[epoch 1, iter   100] loss: 2.100 eplased time 12.039\n",
      "[epoch 1, iter   200] loss: 1.841 eplased time 11.443\n",
      "[epoch 1, iter   300] loss: 1.650 eplased time 11.790\n",
      "[epoch 1, iter   400] loss: 1.549 eplased time 11.596\n",
      "[epoch 1, iter   500] loss: 1.491 eplased time 11.697\n",
      "[epoch 2, iter   100] loss: 1.417 eplased time 11.655\n",
      "[epoch 2, iter   200] loss: 1.379 eplased time 11.931\n",
      "[epoch 2, iter   300] loss: 1.329 eplased time 11.849\n",
      "[epoch 2, iter   400] loss: 1.292 eplased time 11.904\n",
      "[epoch 2, iter   500] loss: 1.264 eplased time 12.097\n",
      "[epoch 3, iter   100] loss: 1.198 eplased time 11.924\n",
      "[epoch 3, iter   200] loss: 1.184 eplased time 11.967\n",
      "[epoch 3, iter   300] loss: 1.145 eplased time 10.470\n",
      "[epoch 3, iter   400] loss: 1.136 eplased time 10.013\n",
      "[epoch 3, iter   500] loss: 1.126 eplased time 10.059\n",
      "[epoch 4, iter   100] loss: 1.052 eplased time 10.887\n",
      "[epoch 4, iter   200] loss: 1.010 eplased time 10.973\n",
      "[epoch 4, iter   300] loss: 1.038 eplased time 11.147\n",
      "[epoch 4, iter   400] loss: 1.025 eplased time 11.726\n",
      "[epoch 4, iter   500] loss: 1.013 eplased time 11.073\n",
      "[epoch 5, iter   100] loss: 0.929 eplased time 10.248\n",
      "[epoch 5, iter   200] loss: 0.951 eplased time 11.095\n",
      "[epoch 5, iter   300] loss: 0.922 eplased time 11.798\n",
      "[epoch 5, iter   400] loss: 0.916 eplased time 11.216\n",
      "[epoch 5, iter   500] loss: 0.920 eplased time 11.594\n",
      "[epoch 6, iter   100] loss: 0.849 eplased time 11.570\n",
      "[epoch 6, iter   200] loss: 0.833 eplased time 11.633\n",
      "[epoch 6, iter   300] loss: 0.855 eplased time 11.773\n",
      "[epoch 6, iter   400] loss: 0.860 eplased time 10.531\n",
      "[epoch 6, iter   500] loss: 0.851 eplased time 11.517\n",
      "[epoch 7, iter   100] loss: 0.756 eplased time 11.104\n",
      "[epoch 7, iter   200] loss: 0.801 eplased time 11.707\n",
      "[epoch 7, iter   300] loss: 0.817 eplased time 11.013\n",
      "[epoch 7, iter   400] loss: 0.783 eplased time 11.639\n",
      "[epoch 7, iter   500] loss: 0.790 eplased time 11.438\n",
      "[epoch 8, iter   100] loss: 0.713 eplased time 10.610\n",
      "[epoch 8, iter   200] loss: 0.740 eplased time 11.568\n",
      "[epoch 8, iter   300] loss: 0.757 eplased time 11.554\n",
      "[epoch 8, iter   400] loss: 0.747 eplased time 11.094\n",
      "[epoch 8, iter   500] loss: 0.735 eplased time 10.099\n",
      "[epoch 9, iter   100] loss: 0.668 eplased time 10.865\n",
      "[epoch 9, iter   200] loss: 0.693 eplased time 11.420\n",
      "[epoch 9, iter   300] loss: 0.688 eplased time 11.801\n",
      "[epoch 9, iter   400] loss: 0.678 eplased time 11.355\n",
      "[epoch 9, iter   500] loss: 0.724 eplased time 11.175\n",
      "[epoch 10, iter   100] loss: 0.622 eplased time 10.648\n",
      "[epoch 10, iter   200] loss: 0.647 eplased time 9.256\n",
      "[epoch 10, iter   300] loss: 0.660 eplased time 11.033\n",
      "[epoch 10, iter   400] loss: 0.655 eplased time 11.057\n",
      "[epoch 10, iter   500] loss: 0.654 eplased time 10.334\n",
      "[epoch 11, iter   100] loss: 0.573 eplased time 11.595\n",
      "[epoch 11, iter   200] loss: 0.600 eplased time 11.162\n",
      "[epoch 11, iter   300] loss: 0.624 eplased time 11.506\n",
      "[epoch 11, iter   400] loss: 0.631 eplased time 11.393\n",
      "[epoch 11, iter   500] loss: 0.620 eplased time 11.659\n",
      "[epoch 12, iter   100] loss: 0.537 eplased time 11.325\n",
      "[epoch 12, iter   200] loss: 0.549 eplased time 10.918\n",
      "[epoch 12, iter   300] loss: 0.584 eplased time 10.161\n",
      "[epoch 12, iter   400] loss: 0.600 eplased time 11.340\n",
      "[epoch 12, iter   500] loss: 0.606 eplased time 10.542\n",
      "[epoch 13, iter   100] loss: 0.497 eplased time 11.303\n",
      "[epoch 13, iter   200] loss: 0.547 eplased time 11.596\n",
      "[epoch 13, iter   300] loss: 0.540 eplased time 10.752\n",
      "[epoch 13, iter   400] loss: 0.575 eplased time 11.412\n",
      "[epoch 13, iter   500] loss: 0.573 eplased time 10.991\n",
      "[epoch 14, iter   100] loss: 0.449 eplased time 11.583\n",
      "[epoch 14, iter   200] loss: 0.497 eplased time 11.685\n",
      "[epoch 14, iter   300] loss: 0.523 eplased time 11.718\n",
      "[epoch 14, iter   400] loss: 0.517 eplased time 11.775\n",
      "[epoch 14, iter   500] loss: 0.551 eplased time 11.773\n",
      "[epoch 15, iter   100] loss: 0.451 eplased time 11.810\n",
      "[epoch 15, iter   200] loss: 0.490 eplased time 11.757\n",
      "[epoch 15, iter   300] loss: 0.490 eplased time 11.794\n",
      "[epoch 15, iter   400] loss: 0.507 eplased time 11.815\n",
      "[epoch 15, iter   500] loss: 0.514 eplased time 11.238\n",
      "[epoch 16, iter   100] loss: 0.394 eplased time 11.771\n",
      "[epoch 16, iter   200] loss: 0.472 eplased time 11.901\n",
      "[epoch 16, iter   300] loss: 0.452 eplased time 11.707\n",
      "[epoch 16, iter   400] loss: 0.478 eplased time 11.989\n",
      "[epoch 16, iter   500] loss: 0.504 eplased time 11.897\n",
      "[epoch 17, iter   100] loss: 0.385 eplased time 12.007\n",
      "[epoch 17, iter   200] loss: 0.426 eplased time 12.086\n",
      "[epoch 17, iter   300] loss: 0.440 eplased time 11.744\n",
      "[epoch 17, iter   400] loss: 0.470 eplased time 11.783\n",
      "[epoch 17, iter   500] loss: 0.463 eplased time 11.805\n",
      "[epoch 18, iter   100] loss: 0.355 eplased time 11.171\n",
      "[epoch 18, iter   200] loss: 0.392 eplased time 11.925\n",
      "[epoch 18, iter   300] loss: 0.419 eplased time 11.130\n",
      "[epoch 18, iter   400] loss: 0.432 eplased time 11.741\n",
      "[epoch 18, iter   500] loss: 0.448 eplased time 11.693\n",
      "[epoch 19, iter   100] loss: 0.343 eplased time 11.661\n",
      "[epoch 19, iter   200] loss: 0.375 eplased time 11.601\n",
      "[epoch 19, iter   300] loss: 0.395 eplased time 11.530\n",
      "[epoch 19, iter   400] loss: 0.420 eplased time 11.534\n",
      "[epoch 19, iter   500] loss: 0.435 eplased time 10.428\n",
      "[epoch 20, iter   100] loss: 0.322 eplased time 10.833\n",
      "[epoch 20, iter   200] loss: 0.352 eplased time 10.401\n",
      "[epoch 20, iter   300] loss: 0.379 eplased time 11.235\n",
      "[epoch 20, iter   400] loss: 0.379 eplased time 11.029\n",
      "[epoch 20, iter   500] loss: 0.401 eplased time 9.781\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 69 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\"\"\"\n",
    "Creating neural networks in pytorch is easy, because a lot of the nuts and bolts\n",
    "involved in training are abstracted away from the user. All we need to do is\n",
    "create a class for our neural network, in this case VGG. \n",
    "\n",
    "Layers are usually implemented as class attributes, and they are put together to\n",
    "define the forward pass in the class's forward function. We also have to write\n",
    "train and test functions, but you will not need to do this for this assignment.\n",
    "However, I strongly encourage all students to take a look at these functions, as\n",
    "well as the dataloading procedure in main().\n",
    "\n",
    "To create layers, we can make use of nn.Sequential, which allows us to combine\n",
    "multiple layers together in a single object. For example, if we want to\n",
    "implement the following network\n",
    "\n",
    "1. convolutional layer, input channels 3, output channels 8, filter size 3\n",
    "2. max-pooling layer, size 2\n",
    "3. ReLU\n",
    "4. fully-connected layer (512->10),\n",
    "\n",
    "we can do something like the following:\n",
    "\n",
    "self.network = nn.Sequential(\n",
    "                nn.Conv2d(3, 8, kernel_size=3, padding=1),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512,10)\n",
    "                )\n",
    "\n",
    "Note that the input size of the linear layer (512) will only be correct depending\n",
    "on the input size of our images. In this case, the input size would need to be\n",
    "16 x 16, since the max pooling layer (of size 2)  will decrease this size to 8x8\n",
    "and there are 8 output channels, giving 8*8*8=512 features derived from the\n",
    "input image. The sizes given in the comments below should work without you\n",
    "having to figure any of this out.\n",
    "\n",
    "Since we are working with CIFAR10, rather than imagenet, we have modified the\n",
    "size of the various layers to work better for smaller images.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    # You will implement a simple version of vgg11 (https://arxiv.org/pdf/1409.1556.pdf)\n",
    "    # Since the shape of image in CIFAR10 is 32x32x3, much smaller than 224x224x3, \n",
    "    # the number of channels and hidden units are decreased compared to the architecture in paper\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Stage 1\n",
    "            # TODO: convolutional layer, input channels 3, output channels 8, filter size 3\n",
    "            # TODO: max-pooling layer, size 2\n",
    "            # We have commented out the function calls you need to make here, so\n",
    "            # you can see an example for the rest of the network. Fill in the\n",
    "            # ?s.\n",
    "\n",
    "            nn.Conv2d(3, 8, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 2\n",
    "            # TODO: convolutional layer, input channels 8, output channels 16, filter size 3\n",
    "            # TODO: max-pooling layer, size 2\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "\n",
    "            # Stage 3\n",
    "            # TODO: convolutional layer, input channels 16, output channels 32, filter size 3\n",
    "            # TODO: convolutional layer, input channels 32, output channels 32, filter size 3\n",
    "            # TODO: max-pooling layer, size 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            #nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            \n",
    "            # Stage 4\n",
    "            # TODO: convolutional layer, input channels 32, output channels 64, filter size 3\n",
    "            # TODO: convolutional layer, input channels 64, output channels 64, filter size 3\n",
    "            # TODO: max-pooling layer, size 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            #nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # Stage 5\n",
    "            # TODO: convolutional layer, input channels 64, output channels 64, filter size 3\n",
    "            # TODO: convolutional layer, input channels 64, output channels 64, filter size 3\n",
    "            # TODO: max-pooling layer, size 2\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            #nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2)\n",
    "        \n",
    "        \n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # TODO: fully-connected layer (64->64)\n",
    "            nn.Linear(64,64),\n",
    "            \n",
    "            # TODO: ReLU\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # here you can try adding more fully-connected layers followed by\n",
    "            # ReLU, if you want.\n",
    "            \n",
    "            # TODO: fully-connected layer (64->10)\n",
    "            nn.Linear(64,10)\n",
    "\n",
    "            # the softmax will be part of the cross entropy loss (defined\n",
    "            # in main()) so we just need to have a linear layer with output size\n",
    "            # equal to the number of classes (10). This is what is accomplished\n",
    "            # by the layer you will implement above.\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # if you decide to change or add anything to conv(), you will need to\n",
    "        # change x.view(-1, num_feats) where num_feats is the number of scalar\n",
    "        # output features from conv(). You will then need to change the first\n",
    "        # input layer in fc() to be num_feats as well.l \n",
    "        x = x.view(-1, 64)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(trainloader, net, criterion, optimizer, device):\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "        start = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            yhat = net.forward(images)\n",
    "            loss = criterion(yhat, labels)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # optimize the network\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                end = time.time()\n",
    "                print('[epoch %d, iter %5d] loss: %.3f eplased time %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100, end-start))\n",
    "                start = time.time()\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "def test(testloader, net, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=True)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False)\n",
    "    net = VGG().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    #optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train(trainloader, net, criterion, optimizer, device)\n",
    "    test(testloader, net, device)\n",
    "    \n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed366be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319aee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c70d95f6b6b98ad3bf971fe1173fba9a78e4f66b001a4059a351e4bfbd57f026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
